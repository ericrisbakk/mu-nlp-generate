{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation was done following this tutorial for song lyrics generation: https://medium.com/coinmonks/word-level-lstm-text-generator-creating-automatic-song-lyrics-with-neural-networks-b8a1617104fb,\n",
    "a continuation of the previous tutorial using word embeddings: https://medium.com/@enriqueav/update-automatic-song-lyrics-creator-with-word-embeddings-e30de94db8d1, and this tutorial for word embeddings: https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "data = pd.read_csv(\"LocalData/ProcessedSongData.csv\")\n",
    "# Ensure that \"token\" and \"corrected\" columns are lists, and not strings of list.\n",
    "# When saving to csv the lists are converted into string.\n",
    "print(\"data loaded.\")\n",
    "# fraction = 1\n",
    "# print(\"Using \", fraction, \" of the dataset.\")\n",
    "# data = data.sample(frac=fraction)\n",
    "# data = data.reset_index(drop=True)\n",
    "# print(\"Sampling finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "The data has already been cleaned, using the script *CleanData.py*, but needs to be converted into token format again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to tokenize.\n",
      "Tokenized clean.\n",
      "Tokenized corrected.\n"
     ]
    }
   ],
   "source": [
    "# Turn sentence into list of words.\n",
    "def tokenize(s):\n",
    "    s_list = [w for w in s.split(' ') if w.strip() != '' or w == '\\r\\n']      \n",
    "    return s_list\n",
    "\n",
    "print(\"Starting to tokenize.\")\n",
    "data[\"t_clean\"] = data.clean.apply(tokenize)\n",
    "print(\"Tokenized clean.\")\n",
    "data[\"t_corrected\"] = data.corrected.apply(tokenize)\n",
    "print(\"Tokenized corrected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['look',\n",
       " 'at',\n",
       " 'her',\n",
       " 'face',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'face',\n",
       " '\\r\\n',\n",
       " 'and',\n",
       " 'it',\n",
       " 'means',\n",
       " 'something',\n",
       " 'special',\n",
       " 'to',\n",
       " 'me',\n",
       " '\\r\\n',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'way',\n",
       " 'that',\n",
       " 'she',\n",
       " 'smiles',\n",
       " 'when',\n",
       " 'she',\n",
       " 'sees',\n",
       " 'me',\n",
       " '\\r\\n',\n",
       " 'how',\n",
       " 'lucky',\n",
       " 'can',\n",
       " 'one',\n",
       " 'fellow',\n",
       " 'be',\n",
       " '\\r\\n',\n",
       " '\\r\\n',\n",
       " 'she',\n",
       " 's',\n",
       " 'just',\n",
       " 'my',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'girl',\n",
       " 'she',\n",
       " 'makes',\n",
       " 'me',\n",
       " 'feel',\n",
       " 'fine',\n",
       " '\\r\\n',\n",
       " 'who',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'she',\n",
       " 'could',\n",
       " 'be',\n",
       " 'mine',\n",
       " '\\r\\n',\n",
       " 'she',\n",
       " 's',\n",
       " 'just',\n",
       " 'my',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'girl',\n",
       " 'without',\n",
       " 'her',\n",
       " 'i',\n",
       " 'm',\n",
       " 'blue',\n",
       " '\\r\\n',\n",
       " 'and',\n",
       " 'if',\n",
       " 'she',\n",
       " 'ever',\n",
       " 'leaves',\n",
       " 'me',\n",
       " 'what',\n",
       " 'could',\n",
       " 'i',\n",
       " 'do',\n",
       " 'what',\n",
       " 'could',\n",
       " 'i',\n",
       " 'do',\n",
       " '\\r\\n',\n",
       " '\\r\\n',\n",
       " 'and',\n",
       " 'when',\n",
       " 'we',\n",
       " 'go',\n",
       " 'for',\n",
       " 'a',\n",
       " 'walk',\n",
       " 'in',\n",
       " 'the',\n",
       " 'park',\n",
       " '\\r\\n',\n",
       " 'and',\n",
       " 'she',\n",
       " 'holds',\n",
       " 'me',\n",
       " 'and',\n",
       " 'squeezes',\n",
       " 'my',\n",
       " 'hand',\n",
       " '\\r\\n',\n",
       " 'we',\n",
       " 'll',\n",
       " 'go',\n",
       " 'on',\n",
       " 'walking',\n",
       " 'for',\n",
       " 'hours',\n",
       " 'and',\n",
       " 'talking',\n",
       " '\\r\\n',\n",
       " 'about',\n",
       " 'all',\n",
       " 'the',\n",
       " 'things',\n",
       " 'that',\n",
       " 'we',\n",
       " 'plan',\n",
       " '\\r\\n',\n",
       " '\\r\\n',\n",
       " 'she',\n",
       " 's',\n",
       " 'just',\n",
       " 'my',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'girl',\n",
       " 'she',\n",
       " 'makes',\n",
       " 'me',\n",
       " 'feel',\n",
       " 'fine',\n",
       " '\\r\\n',\n",
       " 'who',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'she',\n",
       " 'could',\n",
       " 'be',\n",
       " 'mine',\n",
       " '\\r\\n',\n",
       " 'she',\n",
       " 's',\n",
       " 'just',\n",
       " 'my',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'girl',\n",
       " 'without',\n",
       " 'her',\n",
       " 'i',\n",
       " 'm',\n",
       " 'blue',\n",
       " '\\r\\n',\n",
       " 'and',\n",
       " 'if',\n",
       " 'she',\n",
       " 'ever',\n",
       " 'leaves',\n",
       " 'me',\n",
       " 'what',\n",
       " 'could',\n",
       " 'i',\n",
       " 'do',\n",
       " 'what',\n",
       " 'could',\n",
       " 'i',\n",
       " 'do',\n",
       " '\\r\\n',\n",
       " '\\r\\n']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm output looks correct.\n",
    "data.t_corrected[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words total:  15749211\n",
      "Unique words:  61999\n"
     ]
    }
   ],
   "source": [
    "# Create vocab\n",
    "text_values = data.t_corrected.values\n",
    "vocab = Counter()\n",
    "\n",
    "text_in_words = []\n",
    "for song in text_values:\n",
    "    vocab.update(song)\n",
    "    text_in_words.extend(song)\n",
    "\n",
    "print(\"Number of words total: \", len(text_in_words))\n",
    "print(\"Unique words: \", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_keys = sorted(list(vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words before ignoring: 61999\n",
      "Ignoring words with frequency < 2\n",
      "Unique words after ignoring: 40742\n"
     ]
    }
   ],
   "source": [
    "# Calculate word frequency\n",
    "# With a minimum word frequency of 2, all words that only\n",
    "# ever appear once will be ignored.\n",
    "MIN_WORD_FREQUENCY=2\n",
    "\n",
    "ignored_words = set()\n",
    "for k, v in vocab.items():\n",
    "    if vocab[k] < MIN_WORD_FREQUENCY:\n",
    "        ignored_words.add(k)\n",
    "\n",
    "print('Unique words before ignoring:', len(vocab))\n",
    "print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n",
    "words_reduced = sorted(set(vocab.keys()) - ignored_words)\n",
    "print('Unique words after ignoring:', len(words_reduced))\n",
    "\n",
    "\n",
    "#word_indices = dict((c, i) for i, c in enumerate(words_reduced))\n",
    "#indices_word = dict((i, c) for i, c in enumerate(words_reduced))\n",
    "\n",
    "# Because we are not using the reduced vocabulary, do this instead.\n",
    "word_indices = dict((c, i) for i, c in enumerate(vocab))\n",
    "indices_word = dict((i, c) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the vocabulary to a file.\n",
    "def save_list(lines, filename):\n",
    "\t# convert lines to a single blob of text\n",
    "\tdata = '\\n'.join(lines)\n",
    "\t# open file\n",
    "\tfile = open(filename, 'w')\n",
    "\t# write text\n",
    "\tfile.write(data)\n",
    "\t# close file\n",
    "\tfile.close()\n",
    "    \n",
    "# save tokens to a vocabulary file\n",
    "save_list(words_reduced, 'LocalData/vocab_min2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out words that are not in vocab, turn back into strings.\n",
    "#clean_songs = []\n",
    "#c = 0\n",
    "#for song in text_values:\n",
    "#    c += 1\n",
    "#    if c%100 == 0:\n",
    "#        print(c)\n",
    "#    clean_songs.append([w for w in song if w in words_reduced])\n",
    "\n",
    "# Because of a slow computer, I'm skipping this step, and using a fraction of the dataset, \n",
    "# Only using a fraction of the words.\n",
    "clean_songs = text_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word embedding\n",
    "\n",
    "Below we use *gensim* to train a custom word embedding on our song dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "EMBEDDING_SIZE = 100\n",
    "WINDOW_SIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model and keyed vectors, so training does not have to happen again.\n",
    "wv_mod = Word2Vec(clean_songs, size=EMBEDDING_SIZE, window=WINDOW_SIZE, min_count=1)\n",
    "wv_mod.save(\"LocalData/song_word2vec.model\")\n",
    "wv_mod.wv.save(\"LocalData/song_word_vec.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = wv_mod.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.54496038e-01,  1.05630708e+00,  3.95771623e-01, -4.22454953e-01,\n",
       "       -2.53180265e+00,  4.60597456e-01, -6.05708733e-02,  6.86838627e-02,\n",
       "        2.08732295e+00,  1.66664451e-01, -3.04791498e+00,  8.90742958e-01,\n",
       "       -1.61413455e+00, -1.16835706e-01,  9.39812243e-01,  1.94252932e+00,\n",
       "        5.46967447e-01, -4.93695676e-01,  1.42721319e+00, -1.99940360e+00,\n",
       "        1.54394722e+00, -2.29958987e+00,  1.20335591e+00, -3.53519821e+00,\n",
       "       -4.96471941e-01,  2.39508200e+00, -1.02130353e+00,  2.71982241e+00,\n",
       "       -6.38455212e-01,  1.58451009e+00, -9.05888319e-01, -1.35535121e-01,\n",
       "        1.92685497e+00, -1.81356299e+00,  2.09541583e+00,  2.16882300e+00,\n",
       "        3.77132088e-01, -3.77653623e+00,  1.07760155e+00,  1.54926598e+00,\n",
       "        1.55171466e+00, -6.91413105e-01,  3.90740585e+00,  5.69357097e-01,\n",
       "       -1.65043259e+00, -4.10019815e-01,  1.63975847e+00,  2.64878035e+00,\n",
       "        1.27710676e+00, -3.83743095e+00, -1.08813596e+00, -2.11548758e+00,\n",
       "       -1.22665405e+00, -1.15022624e+00, -3.32690454e+00, -4.71450910e-02,\n",
       "       -1.15649986e+00, -2.53158832e+00, -1.64850855e+00, -2.63525039e-01,\n",
       "        9.62427258e-02, -1.77397358e+00, -6.90091789e-01,  5.90317190e-01,\n",
       "        1.33850527e+00,  2.24977493e+00, -1.03912771e+00, -1.48553109e+00,\n",
       "       -5.64911664e-01, -3.91384768e+00,  2.38849354e+00, -4.28274646e-03,\n",
       "       -2.40172982e+00, -7.59012699e-01,  1.54273987e+00,  1.54272604e+00,\n",
       "       -5.58502626e+00, -3.16097903e+00,  3.32548547e+00,  1.50190520e+00,\n",
       "       -3.09016275e+00, -4.28224027e-01, -2.04564738e+00, -1.39387906e+00,\n",
       "       -1.60048223e+00,  5.33103943e-01,  7.52585769e-01, -2.91874385e+00,\n",
       "       -6.80202767e-02, -1.07023776e+00,  7.33199835e-01,  9.45927083e-01,\n",
       "       -8.24905217e-01,  9.31779623e-01, -1.05729854e+00,  1.05861533e+00,\n",
       "        3.66932601e-01, -3.60576582e+00, -3.74094820e+00, -2.34068677e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [wv['best']]\n",
    "wv.most_similar(positive=pos, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"LocalData/song_word_vec.kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset into X and Ys\n",
    "The data is still a list of strings. We need to be able to convert our input to word vectors, and our output needs to be a one-hot-encoding, as the prediction can be interpreted as a sort of classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "SEQUENCE_LEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(clean_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary, from the tokenizer and save it.\n",
    "token_nums = tokenizer.texts_to_sequences([vocab_keys])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a dictionary to file.\n",
    "f = open(\"LocalData/tokenizer_dict.txt\",\"w\")\n",
    "for i in range(len(token_nums)):\n",
    "    f.write((repr(vocab_keys[i]) + \" \" + str(token_nums[i]) + \"\\n\"))\n",
    "            \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two dicts! To look up the indices. Why not.\n",
    "token_to_string = dict()\n",
    "string_to_token = dict()\n",
    "f = open(\"LocalData/tokenizer_dict.txt\",\"r\")\n",
    "for i in range(len(token_nums)):\n",
    "    l = f.readline().split(\" \")\n",
    "    key = l[0]\n",
    "    tok = int(l[1])\n",
    "    # Remove the '.\n",
    "    key = key[1:-1]\n",
    "    token_to_string[tok] = key\n",
    "    string_to_token[key] = tok\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT! This particular thing fucks things up because it uses \\.\n",
    "string_to_token['\\r\\n'] = string_to_token['\\\\r\\\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: 15460961\n"
     ]
    }
   ],
   "source": [
    "# Generate SEQUENCE_LEN words from all songs.\n",
    "STEP = 1\n",
    "sentences = []\n",
    "next_words = []\n",
    "    \n",
    "for song in clean_songs:\n",
    "    if len(song) > SEQUENCE_LEN:\n",
    "        for i in range(0, len(song) - SEQUENCE_LEN, STEP):\n",
    "            sentences.append(text_in_words[i: i + SEQUENCE_LEN])\n",
    "            next_words.append(text_in_words[i + SEQUENCE_LEN])\n",
    "\n",
    "print('Sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator to avoid memory issues.\n",
    "def generator(sentence_list, next_word_list, batch_size):\n",
    "    index = 0\n",
    "    looped = False\n",
    "    while True:\n",
    "        x = np.zeros((batch_size, SEQUENCE_LEN, EMBEDDING_SIZE), dtype=np.float32)\n",
    "        y = np.zeros((batch_size, len(vocab)), dtype=np.bool)\n",
    "        for i in range(batch_size):\n",
    "            # For each word in the sentence fragment, get the vector\n",
    "            for t, w in enumerate(sentence_list[index]):\n",
    "                x[i, t,:] = wv[w]\n",
    "            # Set the appropriate y-value.\n",
    "            y[i, string_to_token[next_word_list[index]]] = 1\n",
    "            # Each batch does a different sentence.\n",
    "            index = index + 1\n",
    "            # Reset the index at the end.\n",
    "            if index == len(sentence_list):\n",
    "                index = 0\n",
    "                looped = True\n",
    "        # Stopping condition: If we have gone around, stop yielding.\n",
    "        if looped:\n",
    "            return None\n",
    "        else:\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[[-1.26525140e+00 -2.17486191e+00 -2.71750259e+00 -1.69165003e+00\n",
      "   -1.62080848e+00 -2.59787512e+00  1.60541451e+00  2.62714553e+00\n",
      "    2.48251629e+00  1.04202032e+00  4.64015901e-01  1.83763325e+00\n",
      "   -6.02256727e+00  1.13758780e-01 -6.55554712e-01  4.86683321e+00\n",
      "    3.31622314e+00 -1.87176251e+00  1.45121396e-01  3.68690848e+00\n",
      "   -1.37359127e-01 -9.09220815e-01 -1.02506888e+00 -4.66403693e-01\n",
      "   -2.41911578e+00  2.78507924e+00 -2.16101453e-01  2.09621549e+00\n",
      "   -3.52564037e-01 -2.67870992e-01 -2.11816001e+00  1.99989164e+00\n",
      "    2.94896215e-01  1.95431507e+00 -1.41456664e+00  2.37476811e-01\n",
      "    1.63989413e+00  2.42088246e+00 -6.09634757e-01 -4.28877020e+00\n",
      "   -3.36652994e+00 -9.72085238e-01  1.55412093e-01  9.62847769e-01\n",
      "    1.40335357e+00  3.55855989e+00 -1.40522063e+00  4.26149145e-02\n",
      "   -1.94994962e+00 -1.10135877e+00  2.52184176e+00  4.50249434e-01\n",
      "   -2.42768908e+00 -1.81290102e+00 -1.05302858e+00  4.25047112e+00\n",
      "    2.09376097e+00  1.25074852e+00  3.36021781e-01  8.13863337e-01\n",
      "   -1.20906413e+00 -3.13292176e-01  4.01615389e-02  6.94168448e-01\n",
      "    1.76251912e+00 -9.27179694e-01 -2.79977059e+00 -2.12466383e+00\n",
      "   -8.61185730e-01 -1.32640088e+00 -1.06266415e+00 -2.48945975e+00\n",
      "   -6.00295544e-01  2.10368228e+00  1.65657091e+00 -5.89022815e-01\n",
      "    1.49692142e+00 -8.81294310e-01  2.26086640e+00 -2.29028821e+00\n",
      "   -3.50760889e+00  2.37797546e+00 -1.21083975e+00  3.76707244e+00\n",
      "    1.98344338e+00 -1.00568581e+00 -1.69632888e+00 -2.11715031e+00\n",
      "    3.80805564e+00 -4.64178413e-01 -3.77615476e+00 -3.50934553e+00\n",
      "   -1.50792682e+00  9.68802392e-01 -9.72205818e-01 -1.49889624e+00\n",
      "   -6.77331463e-02 -7.91426241e-01  8.11709285e-01  1.32365417e+00]\n",
      "  [-3.29533768e+00  3.89906764e+00  9.73395467e-01 -4.02602673e-01\n",
      "   -1.96597219e-01 -1.61064160e+00 -7.86810338e-01  4.84833181e-01\n",
      "   -1.20923746e+00 -5.20461845e+00  1.59636807e+00  5.05824983e-01\n",
      "   -1.23642199e-01  3.30508971e+00  1.46283865e+00 -2.46384287e+00\n",
      "    1.43583894e+00  4.33224916e+00 -2.26000214e+00 -2.69311357e+00\n",
      "    1.87178850e+00 -3.29132986e+00  1.64449584e+00  5.39959908e-01\n",
      "   -1.47721827e+00 -7.16765106e-01 -2.90623331e+00  7.34951556e-01\n",
      "    2.31227279e+00  1.87336755e+00 -2.06440639e+00 -2.16147637e+00\n",
      "   -8.27904344e-01  1.40202177e+00 -4.27344608e+00 -1.76880074e+00\n",
      "   -1.70783901e+00 -2.17936254e+00  2.43021846e+00  1.42241728e+00\n",
      "    4.84612793e-01  8.78195822e-01  1.35193408e+00 -5.87623000e-01\n",
      "   -1.20980144e+00  3.86036545e-01 -4.17007983e-01 -3.44755197e+00\n",
      "   -1.45633173e+00  3.61203104e-01  5.49680054e-01  2.56586045e-01\n",
      "    5.44895828e-01  7.82892287e-01  6.51248455e+00  2.71253377e-01\n",
      "   -1.42629802e+00 -3.16096663e+00 -7.18196929e-01 -1.42164302e+00\n",
      "    4.35195446e-01  2.70900279e-01 -6.62336922e+00  5.50595343e-01\n",
      "    2.70382553e-01  4.33004737e-01  1.72382116e-01  5.98540664e-01\n",
      "   -2.05003667e+00 -6.26759768e-01 -9.88525867e-01  7.74121821e-01\n",
      "   -1.08525586e+00 -3.12404871e-01  2.72647977e+00 -2.99562573e-01\n",
      "   -1.25458002e+00  1.16351676e+00  4.12191331e-01  1.16047144e+00\n",
      "   -8.20354164e-01 -1.47549641e+00  1.66346991e+00 -4.22455102e-01\n",
      "    8.35008860e-01 -2.28640139e-01 -2.52893019e+00  2.37473464e+00\n",
      "   -2.62227345e+00  3.21285772e+00 -4.33640671e+00 -6.08136749e+00\n",
      "    3.25437331e+00 -1.50748596e-01 -2.16738656e-02  7.17618763e-01\n",
      "   -1.26403797e+00 -1.91514230e+00 -1.12285066e+00 -1.23224139e+00]\n",
      "  [ 5.92856228e-01  3.99856734e+00 -1.58757567e+00 -3.27653193e+00\n",
      "    4.97106123e+00 -2.90939003e-01 -3.36986929e-01  1.13415158e+00\n",
      "   -3.58446717e+00  3.12347937e+00 -2.38290095e+00  2.72584534e+00\n",
      "   -6.06799936e+00 -4.41286850e+00  1.89848232e+00  2.33585596e+00\n",
      "   -2.49059725e+00  2.28114200e+00 -2.96595645e+00  1.84407091e+00\n",
      "   -5.94418883e-01 -4.56879377e+00 -3.11332321e+00  1.54704857e+00\n",
      "    2.84681535e+00  5.62951744e-01 -1.24804473e+00 -1.52540207e+00\n",
      "    5.53589523e-01 -6.95256650e-01  1.49345219e+00  7.73837686e-01\n",
      "    1.84125876e+00 -2.10813117e+00  2.52412558e+00  1.50857401e+00\n",
      "   -1.46903768e-01  1.45853055e+00  1.49194372e+00  1.29516527e-01\n",
      "   -1.51409411e+00 -9.37319040e-01  9.14233804e-01  4.64849740e-01\n",
      "   -1.44748163e+00 -2.61683941e-01  2.30281591e+00  1.13113213e+00\n",
      "   -1.72475386e+00 -2.31235519e-01  2.56111574e+00  1.71662235e+00\n",
      "   -9.02750671e-01 -2.80707538e-01 -1.29590929e+00  1.08823383e+00\n",
      "   -2.30147671e-02  1.14149690e+00  1.32874382e+00 -2.11982274e+00\n",
      "   -4.77799922e-02  1.72156751e+00 -2.03590560e+00  1.44290435e+00\n",
      "    1.08461785e+00 -4.79427069e-01  7.39195228e-01  2.14494371e+00\n",
      "    7.34935522e-01 -2.07544804e+00  1.43921566e+00 -2.76350093e+00\n",
      "   -1.48264885e+00 -1.72967538e-01  5.06601095e-01  5.76012790e-01\n",
      "   -2.27072835e+00 -2.34716725e+00 -2.86805415e+00 -3.50256324e+00\n",
      "    1.70890152e+00 -1.36381495e+00  2.25083447e+00 -1.12222219e+00\n",
      "   -1.84769464e+00 -1.49918407e-01  6.77883327e-01 -1.31463218e+00\n",
      "    7.04964221e-01  4.58100033e+00 -1.31933451e+00  7.79372931e-01\n",
      "    1.48409033e+00  4.07835674e+00 -4.15784419e-01  2.51796198e+00\n",
      "   -2.56988049e+00 -2.58338869e-01 -1.32369053e+00  2.42187548e+00]\n",
      "  [-1.10638583e+00  2.61419773e+00 -2.00095630e+00 -3.88702035e+00\n",
      "   -4.10467945e-02 -2.62925005e+00  1.58371854e+00 -7.93362632e-02\n",
      "    3.90674710e-01 -6.10536754e-01 -3.14546794e-01 -1.34523654e+00\n",
      "   -4.64631319e+00 -1.11412786e-01 -1.91561711e+00  1.83932114e+00\n",
      "    3.80908012e-01  1.30822873e+00 -2.28103399e+00 -4.75057483e-01\n",
      "    2.70666027e+00  1.01166594e+00 -4.21630591e-01  1.10265279e+00\n",
      "   -6.19869586e-03 -2.19718194e+00 -2.32991767e+00 -2.70446658e+00\n",
      "    4.26675975e-01  1.26836240e+00 -1.94871545e-01  1.09239757e-01\n",
      "   -1.24621844e+00  4.97677386e-01 -1.16150546e+00  2.65773869e+00\n",
      "    1.85719442e+00 -4.44343984e-01  4.21496296e+00 -2.28446865e+00\n",
      "   -7.14674056e-01  1.80843681e-01  1.27247977e+00  2.36852002e+00\n",
      "   -5.29870450e-01  1.42770004e+00 -7.73033977e-01 -5.43928027e-01\n",
      "   -2.75731730e+00 -9.49946791e-02 -1.29025310e-01 -2.35996103e+00\n",
      "   -3.40213728e+00 -2.05321407e+00  1.14227176e+00  5.36362469e-01\n",
      "   -8.05666983e-01 -5.71865737e-01  7.33626008e-01  2.23876572e+00\n",
      "    2.01040363e+00  1.53046703e+00  5.18627763e-01 -7.87415028e-01\n",
      "    8.50082040e-01 -8.96455884e-01 -1.47967994e+00 -6.94691837e-02\n",
      "    3.08355093e+00 -1.64234793e+00  1.78504527e+00 -1.05730927e+00\n",
      "    5.15266299e-01  1.21543431e+00 -2.71122307e-01 -5.82254469e-01\n",
      "   -1.03911400e+00  7.33421370e-02  2.76818037e+00  2.08827519e+00\n",
      "   -3.25415587e+00  1.26077962e+00  9.12358344e-01  2.86541271e+00\n",
      "    8.66800904e-01 -1.92954922e+00 -1.21673083e+00 -3.95975232e+00\n",
      "    1.23088896e+00 -1.28631675e+00 -1.43235171e+00  5.68858147e-01\n",
      "    1.90201163e+00  9.03744280e-01 -4.29645586e+00  1.28200042e+00\n",
      "    3.56758803e-01  1.90045071e+00  5.46803761e+00  8.95003200e-01]\n",
      "  [ 6.07646108e-01  1.48261237e+00 -1.81842065e+00 -2.16715550e+00\n",
      "   -1.05272043e+00  1.25311887e+00  9.00569558e-01  1.55517590e+00\n",
      "   -1.57310867e+00  3.48156953e+00 -2.21760178e+00 -3.17695290e-01\n",
      "   -2.85571551e+00 -9.21914935e-01 -2.35557842e+00  2.96048665e+00\n",
      "   -4.36026901e-01 -1.42016137e+00 -2.68290639e-01 -2.31150341e+00\n",
      "   -1.24794197e+00 -2.70023870e+00  1.95143580e+00 -1.44959795e+00\n",
      "   -2.09556746e+00 -1.96321654e+00  9.91507694e-02 -3.70586038e-01\n",
      "   -3.09684098e-01  2.93000603e+00 -1.31096494e+00 -1.11648393e+00\n",
      "   -1.37530959e+00 -9.18803275e-01  4.71577263e+00 -6.57968283e-01\n",
      "    1.36764979e+00 -1.01315701e+00 -1.69113207e+00  1.60116148e+00\n",
      "    2.19467926e+00 -4.52978611e+00  1.60696781e+00  1.88771212e+00\n",
      "    5.81342041e-01  3.29892540e+00 -2.52068806e+00 -1.85572445e+00\n",
      "    8.35395992e-01 -3.71722370e-01 -1.75675914e-01  1.37595975e+00\n",
      "   -1.84795117e+00 -3.92610621e+00  1.15026748e+00  2.68922496e+00\n",
      "   -1.45486283e+00  1.82712626e+00  1.47848821e+00 -3.41744125e-01\n",
      "    3.02503443e+00 -8.00639153e-01  1.75875157e-01  1.96165478e+00\n",
      "   -1.03516686e+00  2.74664187e+00 -1.01212859e+00 -3.82903790e+00\n",
      "   -2.26994827e-01 -2.23399892e-01  4.82884347e-02  8.07850286e-02\n",
      "   -2.86389440e-01  5.27227998e-01  5.74036598e-01  1.16077244e+00\n",
      "   -8.13196898e-01  6.59161747e-01 -9.01446342e-01  1.19830251e+00\n",
      "   -1.17552125e+00  1.75506473e+00  2.12410045e+00 -3.25997353e+00\n",
      "   -6.04537487e-01  8.83872390e-01 -3.67994022e+00 -8.03684056e-01\n",
      "    9.21562076e-01  4.92236674e-01 -1.01429677e+00 -1.30825233e+00\n",
      "   -2.94180632e-01  2.07238269e+00  2.01282680e-01 -2.30839506e-01\n",
      "    1.83988139e-01  1.31270730e+00  1.57355607e-01  9.85155582e-01]]]\n",
      "\n",
      "y:\n",
      "[[False False False ... False False False]]\n",
      "X: \n",
      "[[[-3.29533768e+00  3.89906764e+00  9.73395467e-01 -4.02602673e-01\n",
      "   -1.96597219e-01 -1.61064160e+00 -7.86810338e-01  4.84833181e-01\n",
      "   -1.20923746e+00 -5.20461845e+00  1.59636807e+00  5.05824983e-01\n",
      "   -1.23642199e-01  3.30508971e+00  1.46283865e+00 -2.46384287e+00\n",
      "    1.43583894e+00  4.33224916e+00 -2.26000214e+00 -2.69311357e+00\n",
      "    1.87178850e+00 -3.29132986e+00  1.64449584e+00  5.39959908e-01\n",
      "   -1.47721827e+00 -7.16765106e-01 -2.90623331e+00  7.34951556e-01\n",
      "    2.31227279e+00  1.87336755e+00 -2.06440639e+00 -2.16147637e+00\n",
      "   -8.27904344e-01  1.40202177e+00 -4.27344608e+00 -1.76880074e+00\n",
      "   -1.70783901e+00 -2.17936254e+00  2.43021846e+00  1.42241728e+00\n",
      "    4.84612793e-01  8.78195822e-01  1.35193408e+00 -5.87623000e-01\n",
      "   -1.20980144e+00  3.86036545e-01 -4.17007983e-01 -3.44755197e+00\n",
      "   -1.45633173e+00  3.61203104e-01  5.49680054e-01  2.56586045e-01\n",
      "    5.44895828e-01  7.82892287e-01  6.51248455e+00  2.71253377e-01\n",
      "   -1.42629802e+00 -3.16096663e+00 -7.18196929e-01 -1.42164302e+00\n",
      "    4.35195446e-01  2.70900279e-01 -6.62336922e+00  5.50595343e-01\n",
      "    2.70382553e-01  4.33004737e-01  1.72382116e-01  5.98540664e-01\n",
      "   -2.05003667e+00 -6.26759768e-01 -9.88525867e-01  7.74121821e-01\n",
      "   -1.08525586e+00 -3.12404871e-01  2.72647977e+00 -2.99562573e-01\n",
      "   -1.25458002e+00  1.16351676e+00  4.12191331e-01  1.16047144e+00\n",
      "   -8.20354164e-01 -1.47549641e+00  1.66346991e+00 -4.22455102e-01\n",
      "    8.35008860e-01 -2.28640139e-01 -2.52893019e+00  2.37473464e+00\n",
      "   -2.62227345e+00  3.21285772e+00 -4.33640671e+00 -6.08136749e+00\n",
      "    3.25437331e+00 -1.50748596e-01 -2.16738656e-02  7.17618763e-01\n",
      "   -1.26403797e+00 -1.91514230e+00 -1.12285066e+00 -1.23224139e+00]\n",
      "  [ 5.92856228e-01  3.99856734e+00 -1.58757567e+00 -3.27653193e+00\n",
      "    4.97106123e+00 -2.90939003e-01 -3.36986929e-01  1.13415158e+00\n",
      "   -3.58446717e+00  3.12347937e+00 -2.38290095e+00  2.72584534e+00\n",
      "   -6.06799936e+00 -4.41286850e+00  1.89848232e+00  2.33585596e+00\n",
      "   -2.49059725e+00  2.28114200e+00 -2.96595645e+00  1.84407091e+00\n",
      "   -5.94418883e-01 -4.56879377e+00 -3.11332321e+00  1.54704857e+00\n",
      "    2.84681535e+00  5.62951744e-01 -1.24804473e+00 -1.52540207e+00\n",
      "    5.53589523e-01 -6.95256650e-01  1.49345219e+00  7.73837686e-01\n",
      "    1.84125876e+00 -2.10813117e+00  2.52412558e+00  1.50857401e+00\n",
      "   -1.46903768e-01  1.45853055e+00  1.49194372e+00  1.29516527e-01\n",
      "   -1.51409411e+00 -9.37319040e-01  9.14233804e-01  4.64849740e-01\n",
      "   -1.44748163e+00 -2.61683941e-01  2.30281591e+00  1.13113213e+00\n",
      "   -1.72475386e+00 -2.31235519e-01  2.56111574e+00  1.71662235e+00\n",
      "   -9.02750671e-01 -2.80707538e-01 -1.29590929e+00  1.08823383e+00\n",
      "   -2.30147671e-02  1.14149690e+00  1.32874382e+00 -2.11982274e+00\n",
      "   -4.77799922e-02  1.72156751e+00 -2.03590560e+00  1.44290435e+00\n",
      "    1.08461785e+00 -4.79427069e-01  7.39195228e-01  2.14494371e+00\n",
      "    7.34935522e-01 -2.07544804e+00  1.43921566e+00 -2.76350093e+00\n",
      "   -1.48264885e+00 -1.72967538e-01  5.06601095e-01  5.76012790e-01\n",
      "   -2.27072835e+00 -2.34716725e+00 -2.86805415e+00 -3.50256324e+00\n",
      "    1.70890152e+00 -1.36381495e+00  2.25083447e+00 -1.12222219e+00\n",
      "   -1.84769464e+00 -1.49918407e-01  6.77883327e-01 -1.31463218e+00\n",
      "    7.04964221e-01  4.58100033e+00 -1.31933451e+00  7.79372931e-01\n",
      "    1.48409033e+00  4.07835674e+00 -4.15784419e-01  2.51796198e+00\n",
      "   -2.56988049e+00 -2.58338869e-01 -1.32369053e+00  2.42187548e+00]\n",
      "  [-1.10638583e+00  2.61419773e+00 -2.00095630e+00 -3.88702035e+00\n",
      "   -4.10467945e-02 -2.62925005e+00  1.58371854e+00 -7.93362632e-02\n",
      "    3.90674710e-01 -6.10536754e-01 -3.14546794e-01 -1.34523654e+00\n",
      "   -4.64631319e+00 -1.11412786e-01 -1.91561711e+00  1.83932114e+00\n",
      "    3.80908012e-01  1.30822873e+00 -2.28103399e+00 -4.75057483e-01\n",
      "    2.70666027e+00  1.01166594e+00 -4.21630591e-01  1.10265279e+00\n",
      "   -6.19869586e-03 -2.19718194e+00 -2.32991767e+00 -2.70446658e+00\n",
      "    4.26675975e-01  1.26836240e+00 -1.94871545e-01  1.09239757e-01\n",
      "   -1.24621844e+00  4.97677386e-01 -1.16150546e+00  2.65773869e+00\n",
      "    1.85719442e+00 -4.44343984e-01  4.21496296e+00 -2.28446865e+00\n",
      "   -7.14674056e-01  1.80843681e-01  1.27247977e+00  2.36852002e+00\n",
      "   -5.29870450e-01  1.42770004e+00 -7.73033977e-01 -5.43928027e-01\n",
      "   -2.75731730e+00 -9.49946791e-02 -1.29025310e-01 -2.35996103e+00\n",
      "   -3.40213728e+00 -2.05321407e+00  1.14227176e+00  5.36362469e-01\n",
      "   -8.05666983e-01 -5.71865737e-01  7.33626008e-01  2.23876572e+00\n",
      "    2.01040363e+00  1.53046703e+00  5.18627763e-01 -7.87415028e-01\n",
      "    8.50082040e-01 -8.96455884e-01 -1.47967994e+00 -6.94691837e-02\n",
      "    3.08355093e+00 -1.64234793e+00  1.78504527e+00 -1.05730927e+00\n",
      "    5.15266299e-01  1.21543431e+00 -2.71122307e-01 -5.82254469e-01\n",
      "   -1.03911400e+00  7.33421370e-02  2.76818037e+00  2.08827519e+00\n",
      "   -3.25415587e+00  1.26077962e+00  9.12358344e-01  2.86541271e+00\n",
      "    8.66800904e-01 -1.92954922e+00 -1.21673083e+00 -3.95975232e+00\n",
      "    1.23088896e+00 -1.28631675e+00 -1.43235171e+00  5.68858147e-01\n",
      "    1.90201163e+00  9.03744280e-01 -4.29645586e+00  1.28200042e+00\n",
      "    3.56758803e-01  1.90045071e+00  5.46803761e+00  8.95003200e-01]\n",
      "  [ 6.07646108e-01  1.48261237e+00 -1.81842065e+00 -2.16715550e+00\n",
      "   -1.05272043e+00  1.25311887e+00  9.00569558e-01  1.55517590e+00\n",
      "   -1.57310867e+00  3.48156953e+00 -2.21760178e+00 -3.17695290e-01\n",
      "   -2.85571551e+00 -9.21914935e-01 -2.35557842e+00  2.96048665e+00\n",
      "   -4.36026901e-01 -1.42016137e+00 -2.68290639e-01 -2.31150341e+00\n",
      "   -1.24794197e+00 -2.70023870e+00  1.95143580e+00 -1.44959795e+00\n",
      "   -2.09556746e+00 -1.96321654e+00  9.91507694e-02 -3.70586038e-01\n",
      "   -3.09684098e-01  2.93000603e+00 -1.31096494e+00 -1.11648393e+00\n",
      "   -1.37530959e+00 -9.18803275e-01  4.71577263e+00 -6.57968283e-01\n",
      "    1.36764979e+00 -1.01315701e+00 -1.69113207e+00  1.60116148e+00\n",
      "    2.19467926e+00 -4.52978611e+00  1.60696781e+00  1.88771212e+00\n",
      "    5.81342041e-01  3.29892540e+00 -2.52068806e+00 -1.85572445e+00\n",
      "    8.35395992e-01 -3.71722370e-01 -1.75675914e-01  1.37595975e+00\n",
      "   -1.84795117e+00 -3.92610621e+00  1.15026748e+00  2.68922496e+00\n",
      "   -1.45486283e+00  1.82712626e+00  1.47848821e+00 -3.41744125e-01\n",
      "    3.02503443e+00 -8.00639153e-01  1.75875157e-01  1.96165478e+00\n",
      "   -1.03516686e+00  2.74664187e+00 -1.01212859e+00 -3.82903790e+00\n",
      "   -2.26994827e-01 -2.23399892e-01  4.82884347e-02  8.07850286e-02\n",
      "   -2.86389440e-01  5.27227998e-01  5.74036598e-01  1.16077244e+00\n",
      "   -8.13196898e-01  6.59161747e-01 -9.01446342e-01  1.19830251e+00\n",
      "   -1.17552125e+00  1.75506473e+00  2.12410045e+00 -3.25997353e+00\n",
      "   -6.04537487e-01  8.83872390e-01 -3.67994022e+00 -8.03684056e-01\n",
      "    9.21562076e-01  4.92236674e-01 -1.01429677e+00 -1.30825233e+00\n",
      "   -2.94180632e-01  2.07238269e+00  2.01282680e-01 -2.30839506e-01\n",
      "    1.83988139e-01  1.31270730e+00  1.57355607e-01  9.85155582e-01]\n",
      "  [-1.56987071e+00  1.22022986e+00 -1.76657891e+00 -3.92428935e-01\n",
      "    2.40775064e-01  9.38882053e-01  1.23026958e-02 -1.10580973e-01\n",
      "    6.17324710e-01 -3.22350049e+00 -5.26571751e-01 -1.00513518e+00\n",
      "   -1.76897943e+00 -2.21656728e+00 -2.20532966e+00 -3.12376928e+00\n",
      "    2.51373827e-01 -2.62683320e+00  2.16492844e+00  9.21624660e-01\n",
      "   -1.52286148e+00 -6.17391337e-03 -6.58236444e-01  4.75081533e-01\n",
      "    1.91209346e-01 -1.73056805e+00 -7.87174642e-01 -8.94084156e-01\n",
      "   -2.66800404e-01  1.25927162e+00  1.83589888e+00  1.92013788e+00\n",
      "    9.84338224e-01  8.17920029e-01 -1.93738848e-01 -3.47006106e+00\n",
      "    4.38305795e-01 -1.53365001e-01 -1.16755033e+00 -3.12790108e+00\n",
      "   -1.44838154e+00 -4.23089218e+00 -7.64727056e-01  1.14766181e+00\n",
      "    2.18146753e+00  1.41578388e+00 -3.93726420e+00 -2.92003602e-01\n",
      "   -1.76158130e+00  9.48960185e-01  9.27506864e-01 -3.48344259e-02\n",
      "   -4.61617351e-01 -2.12250566e+00 -4.25976181e+00  5.02884865e-01\n",
      "   -1.82126009e+00  5.51420152e-01  1.16969362e-01  1.51302314e+00\n",
      "    3.46736729e-01  4.22892451e-01 -1.08115733e+00  8.78164172e-01\n",
      "    8.30603063e-01 -1.13731897e+00 -3.12331557e-01 -1.82399452e+00\n",
      "    2.59827703e-01 -4.16108787e-01  3.36200213e+00  1.82923043e+00\n",
      "   -4.12397242e+00  2.34350920e-01  3.62368536e+00 -6.34621561e-01\n",
      "    2.16047859e+00  2.11686468e+00  9.89196777e-01  3.43282247e+00\n",
      "   -3.61810654e-01  4.38701957e-01  7.43654892e-02 -3.87668037e+00\n",
      "    4.14113492e-01 -1.34073579e+00 -1.70415878e-01 -8.56201798e-02\n",
      "    3.89798701e-01  1.17060745e+00 -1.55686662e-01 -1.48822582e+00\n",
      "   -3.78652239e+00  1.65051651e+00 -1.22056210e+00 -1.16919255e+00\n",
      "   -1.30032980e+00  1.73608605e-02 -2.00387549e+00  1.34899545e+00]]]\n",
      "\n",
      "y:\n",
      "[[False False False ... False False False]]\n",
      "X: \n",
      "[[[ 0.5928562   3.9985673  -1.5875757  -3.276532    4.971061\n",
      "   -0.290939   -0.33698693  1.1341516  -3.5844672   3.1234794\n",
      "   -2.382901    2.7258453  -6.0679994  -4.4128685   1.8984823\n",
      "    2.335856   -2.4905972   2.281142   -2.9659564   1.8440709\n",
      "   -0.5944189  -4.568794   -3.1133232   1.5470486   2.8468153\n",
      "    0.56295174 -1.2480447  -1.5254021   0.5535895  -0.69525665\n",
      "    1.4934522   0.7738377   1.8412588  -2.1081312   2.5241256\n",
      "    1.508574   -0.14690377  1.4585305   1.4919437   0.12951653\n",
      "   -1.5140941  -0.93731904  0.9142338   0.46484974 -1.4474816\n",
      "   -0.26168394  2.302816    1.1311321  -1.7247539  -0.23123552\n",
      "    2.5611157   1.7166224  -0.9027507  -0.28070754 -1.2959093\n",
      "    1.0882338  -0.02301477  1.1414969   1.3287438  -2.1198227\n",
      "   -0.04777999  1.7215675  -2.0359056   1.4429044   1.0846179\n",
      "   -0.47942707  0.7391952   2.1449437   0.7349355  -2.075448\n",
      "    1.4392157  -2.763501   -1.4826488  -0.17296754  0.5066011\n",
      "    0.5760128  -2.2707283  -2.3471673  -2.8680542  -3.5025632\n",
      "    1.7089015  -1.363815    2.2508345  -1.1222222  -1.8476946\n",
      "   -0.1499184   0.6778833  -1.3146322   0.7049642   4.5810003\n",
      "   -1.3193345   0.77937293  1.4840903   4.0783567  -0.41578442\n",
      "    2.517962   -2.5698805  -0.25833887 -1.3236905   2.4218755 ]\n",
      "  [-1.1063858   2.6141977  -2.0009563  -3.8870203  -0.04104679\n",
      "   -2.62925     1.5837185  -0.07933626  0.3906747  -0.61053675\n",
      "   -0.3145468  -1.3452365  -4.646313   -0.11141279 -1.9156171\n",
      "    1.8393211   0.380908    1.3082287  -2.281034   -0.47505748\n",
      "    2.7066603   1.0116659  -0.4216306   1.1026528  -0.0061987\n",
      "   -2.197182   -2.3299177  -2.7044666   0.42667598  1.2683624\n",
      "   -0.19487154  0.10923976 -1.2462184   0.4976774  -1.1615055\n",
      "    2.6577387   1.8571944  -0.44434398  4.214963   -2.2844687\n",
      "   -0.71467406  0.18084368  1.2724798   2.36852    -0.52987045\n",
      "    1.4277     -0.773034   -0.543928   -2.7573173  -0.09499468\n",
      "   -0.12902531 -2.359961   -3.4021373  -2.053214    1.1422718\n",
      "    0.53636247 -0.805667   -0.57186574  0.733626    2.2387657\n",
      "    2.0104036   1.530467    0.51862776 -0.787415    0.85008204\n",
      "   -0.8964559  -1.47968    -0.06946918  3.083551   -1.6423479\n",
      "    1.7850453  -1.0573093   0.5152663   1.2154343  -0.2711223\n",
      "   -0.58225447 -1.039114    0.07334214  2.7681804   2.0882752\n",
      "   -3.2541559   1.2607796   0.91235834  2.8654127   0.8668009\n",
      "   -1.9295492  -1.2167308  -3.9597523   1.230889   -1.2863168\n",
      "   -1.4323517   0.56885815  1.9020116   0.9037443  -4.296456\n",
      "    1.2820004   0.3567588   1.9004507   5.4680376   0.8950032 ]\n",
      "  [ 0.6076461   1.4826124  -1.8184206  -2.1671555  -1.0527204\n",
      "    1.2531189   0.90056956  1.5551759  -1.5731087   3.4815695\n",
      "   -2.2176018  -0.3176953  -2.8557155  -0.92191494 -2.3555784\n",
      "    2.9604867  -0.4360269  -1.4201614  -0.26829064 -2.3115034\n",
      "   -1.247942   -2.7002387   1.9514358  -1.449598   -2.0955675\n",
      "   -1.9632165   0.09915077 -0.37058604 -0.3096841   2.930006\n",
      "   -1.310965   -1.1164839  -1.3753096  -0.9188033   4.7157726\n",
      "   -0.6579683   1.3676498  -1.013157   -1.6911321   1.6011615\n",
      "    2.1946793  -4.529786    1.6069678   1.8877121   0.58134204\n",
      "    3.2989254  -2.520688   -1.8557245   0.835396   -0.37172237\n",
      "   -0.17567591  1.3759598  -1.8479512  -3.9261062   1.1502675\n",
      "    2.689225   -1.4548628   1.8271263   1.4784882  -0.34174412\n",
      "    3.0250344  -0.80063915  0.17587516  1.9616548  -1.0351669\n",
      "    2.7466419  -1.0121286  -3.829038   -0.22699483 -0.22339989\n",
      "    0.04828843  0.08078503 -0.28638944  0.527228    0.5740366\n",
      "    1.1607724  -0.8131969   0.65916175 -0.90144634  1.1983025\n",
      "   -1.1755213   1.7550647   2.1241004  -3.2599735  -0.6045375\n",
      "    0.8838724  -3.6799402  -0.80368406  0.9215621   0.49223667\n",
      "   -1.0142968  -1.3082523  -0.29418063  2.0723827   0.20128268\n",
      "   -0.2308395   0.18398814  1.3127073   0.1573556   0.9851556 ]\n",
      "  [-1.5698707   1.2202299  -1.7665789  -0.39242893  0.24077506\n",
      "    0.93888205  0.0123027  -0.11058097  0.6173247  -3.2235005\n",
      "   -0.52657175 -1.0051352  -1.7689794  -2.2165673  -2.2053297\n",
      "   -3.1237693   0.25137383 -2.6268332   2.1649284   0.92162466\n",
      "   -1.5228615  -0.00617391 -0.65823644  0.47508153  0.19120935\n",
      "   -1.730568   -0.78717464 -0.89408416 -0.2668004   1.2592716\n",
      "    1.8358989   1.9201379   0.9843382   0.81792    -0.19373885\n",
      "   -3.470061    0.4383058  -0.153365   -1.1675503  -3.127901\n",
      "   -1.4483815  -4.230892   -0.76472706  1.1476618   2.1814675\n",
      "    1.4157839  -3.9372642  -0.2920036  -1.7615813   0.9489602\n",
      "    0.92750686 -0.03483443 -0.46161735 -2.1225057  -4.259762\n",
      "    0.50288486 -1.8212601   0.55142015  0.11696936  1.5130231\n",
      "    0.34673673  0.42289245 -1.0811573   0.8781642   0.83060306\n",
      "   -1.137319   -0.31233156 -1.8239945   0.2598277  -0.4161088\n",
      "    3.3620021   1.8292304  -4.1239724   0.23435092  3.6236854\n",
      "   -0.63462156  2.1604786   2.1168647   0.9891968   3.4328225\n",
      "   -0.36181065  0.43870196  0.07436549 -3.8766804   0.4141135\n",
      "   -1.3407358  -0.17041588 -0.08562018  0.3897987   1.1706074\n",
      "   -0.15568666 -1.4882258  -3.7865224   1.6505165  -1.2205621\n",
      "   -1.1691926  -1.3003298   0.01736086 -2.0038755   1.3489954 ]\n",
      "  [-2.3543086   1.5711281   0.6781179  -0.25551656 -0.38900065\n",
      "    1.6135992   2.6590319  -0.43829447 -1.0410856  -1.5015258\n",
      "   -2.0319548   1.4794507  -4.8004837  -3.0774274   1.3397582\n",
      "    0.82829154 -3.7451031  -0.23459041  1.9209489   1.3456584\n",
      "   -0.18605064 -1.3953729  -0.29109177  1.5516727  -0.9196038\n",
      "   -0.26929933  1.0445118  -3.964381    2.195807    0.5252962\n",
      "   -0.6166016  -0.19051811  1.3555189   1.029685    1.062792\n",
      "    0.28212056  0.15797052 -1.5051016  -1.2758598   1.4063493\n",
      "    1.6402774  -2.9643593   0.2672064   0.10114635  1.7237924\n",
      "    2.3992565   0.7649153  -1.7935115  -0.05254006  1.0960087\n",
      "    1.2949128   0.32008132  0.43295327 -2.263622    0.41430292\n",
      "    1.9851656  -2.2921946   2.6615927   2.4680684  -0.02525874\n",
      "    2.5429075   2.942506    1.7775179  -0.5292414   1.40715\n",
      "    1.3437902  -0.09238902 -0.715927   -0.25621727 -1.2886151\n",
      "    2.579778    1.204933   -0.6935196  -4.460212    1.7314092\n",
      "    1.3642921  -2.1640139   0.14607194  0.64921254 -2.003338\n",
      "    0.16374187 -0.29953638  1.2702949   0.33621025 -1.4837034\n",
      "   -1.3119931   1.5296751   0.43552196 -3.8295093  -1.105078\n",
      "   -2.9571974   0.5395242   1.4110634  -1.891544    1.839261\n",
      "   -1.0103552   1.4214919   0.81878555 -3.1543305  -2.4490614 ]]]\n",
      "\n",
      "y:\n",
      "[[False False False ... False False False]]\n",
      "X: \n",
      "[[[-1.1063858   2.6141977  -2.0009563  -3.8870203  -0.04104679\n",
      "   -2.62925     1.5837185  -0.07933626  0.3906747  -0.61053675\n",
      "   -0.3145468  -1.3452365  -4.646313   -0.11141279 -1.9156171\n",
      "    1.8393211   0.380908    1.3082287  -2.281034   -0.47505748\n",
      "    2.7066603   1.0116659  -0.4216306   1.1026528  -0.0061987\n",
      "   -2.197182   -2.3299177  -2.7044666   0.42667598  1.2683624\n",
      "   -0.19487154  0.10923976 -1.2462184   0.4976774  -1.1615055\n",
      "    2.6577387   1.8571944  -0.44434398  4.214963   -2.2844687\n",
      "   -0.71467406  0.18084368  1.2724798   2.36852    -0.52987045\n",
      "    1.4277     -0.773034   -0.543928   -2.7573173  -0.09499468\n",
      "   -0.12902531 -2.359961   -3.4021373  -2.053214    1.1422718\n",
      "    0.53636247 -0.805667   -0.57186574  0.733626    2.2387657\n",
      "    2.0104036   1.530467    0.51862776 -0.787415    0.85008204\n",
      "   -0.8964559  -1.47968    -0.06946918  3.083551   -1.6423479\n",
      "    1.7850453  -1.0573093   0.5152663   1.2154343  -0.2711223\n",
      "   -0.58225447 -1.039114    0.07334214  2.7681804   2.0882752\n",
      "   -3.2541559   1.2607796   0.91235834  2.8654127   0.8668009\n",
      "   -1.9295492  -1.2167308  -3.9597523   1.230889   -1.2863168\n",
      "   -1.4323517   0.56885815  1.9020116   0.9037443  -4.296456\n",
      "    1.2820004   0.3567588   1.9004507   5.4680376   0.8950032 ]\n",
      "  [ 0.6076461   1.4826124  -1.8184206  -2.1671555  -1.0527204\n",
      "    1.2531189   0.90056956  1.5551759  -1.5731087   3.4815695\n",
      "   -2.2176018  -0.3176953  -2.8557155  -0.92191494 -2.3555784\n",
      "    2.9604867  -0.4360269  -1.4201614  -0.26829064 -2.3115034\n",
      "   -1.247942   -2.7002387   1.9514358  -1.449598   -2.0955675\n",
      "   -1.9632165   0.09915077 -0.37058604 -0.3096841   2.930006\n",
      "   -1.310965   -1.1164839  -1.3753096  -0.9188033   4.7157726\n",
      "   -0.6579683   1.3676498  -1.013157   -1.6911321   1.6011615\n",
      "    2.1946793  -4.529786    1.6069678   1.8877121   0.58134204\n",
      "    3.2989254  -2.520688   -1.8557245   0.835396   -0.37172237\n",
      "   -0.17567591  1.3759598  -1.8479512  -3.9261062   1.1502675\n",
      "    2.689225   -1.4548628   1.8271263   1.4784882  -0.34174412\n",
      "    3.0250344  -0.80063915  0.17587516  1.9616548  -1.0351669\n",
      "    2.7466419  -1.0121286  -3.829038   -0.22699483 -0.22339989\n",
      "    0.04828843  0.08078503 -0.28638944  0.527228    0.5740366\n",
      "    1.1607724  -0.8131969   0.65916175 -0.90144634  1.1983025\n",
      "   -1.1755213   1.7550647   2.1241004  -3.2599735  -0.6045375\n",
      "    0.8838724  -3.6799402  -0.80368406  0.9215621   0.49223667\n",
      "   -1.0142968  -1.3082523  -0.29418063  2.0723827   0.20128268\n",
      "   -0.2308395   0.18398814  1.3127073   0.1573556   0.9851556 ]\n",
      "  [-1.5698707   1.2202299  -1.7665789  -0.39242893  0.24077506\n",
      "    0.93888205  0.0123027  -0.11058097  0.6173247  -3.2235005\n",
      "   -0.52657175 -1.0051352  -1.7689794  -2.2165673  -2.2053297\n",
      "   -3.1237693   0.25137383 -2.6268332   2.1649284   0.92162466\n",
      "   -1.5228615  -0.00617391 -0.65823644  0.47508153  0.19120935\n",
      "   -1.730568   -0.78717464 -0.89408416 -0.2668004   1.2592716\n",
      "    1.8358989   1.9201379   0.9843382   0.81792    -0.19373885\n",
      "   -3.470061    0.4383058  -0.153365   -1.1675503  -3.127901\n",
      "   -1.4483815  -4.230892   -0.76472706  1.1476618   2.1814675\n",
      "    1.4157839  -3.9372642  -0.2920036  -1.7615813   0.9489602\n",
      "    0.92750686 -0.03483443 -0.46161735 -2.1225057  -4.259762\n",
      "    0.50288486 -1.8212601   0.55142015  0.11696936  1.5130231\n",
      "    0.34673673  0.42289245 -1.0811573   0.8781642   0.83060306\n",
      "   -1.137319   -0.31233156 -1.8239945   0.2598277  -0.4161088\n",
      "    3.3620021   1.8292304  -4.1239724   0.23435092  3.6236854\n",
      "   -0.63462156  2.1604786   2.1168647   0.9891968   3.4328225\n",
      "   -0.36181065  0.43870196  0.07436549 -3.8766804   0.4141135\n",
      "   -1.3407358  -0.17041588 -0.08562018  0.3897987   1.1706074\n",
      "   -0.15568666 -1.4882258  -3.7865224   1.6505165  -1.2205621\n",
      "   -1.1691926  -1.3003298   0.01736086 -2.0038755   1.3489954 ]\n",
      "  [-2.3543086   1.5711281   0.6781179  -0.25551656 -0.38900065\n",
      "    1.6135992   2.6590319  -0.43829447 -1.0410856  -1.5015258\n",
      "   -2.0319548   1.4794507  -4.8004837  -3.0774274   1.3397582\n",
      "    0.82829154 -3.7451031  -0.23459041  1.9209489   1.3456584\n",
      "   -0.18605064 -1.3953729  -0.29109177  1.5516727  -0.9196038\n",
      "   -0.26929933  1.0445118  -3.964381    2.195807    0.5252962\n",
      "   -0.6166016  -0.19051811  1.3555189   1.029685    1.062792\n",
      "    0.28212056  0.15797052 -1.5051016  -1.2758598   1.4063493\n",
      "    1.6402774  -2.9643593   0.2672064   0.10114635  1.7237924\n",
      "    2.3992565   0.7649153  -1.7935115  -0.05254006  1.0960087\n",
      "    1.2949128   0.32008132  0.43295327 -2.263622    0.41430292\n",
      "    1.9851656  -2.2921946   2.6615927   2.4680684  -0.02525874\n",
      "    2.5429075   2.942506    1.7775179  -0.5292414   1.40715\n",
      "    1.3437902  -0.09238902 -0.715927   -0.25621727 -1.2886151\n",
      "    2.579778    1.204933   -0.6935196  -4.460212    1.7314092\n",
      "    1.3642921  -2.1640139   0.14607194  0.64921254 -2.003338\n",
      "    0.16374187 -0.29953638  1.2702949   0.33621025 -1.4837034\n",
      "   -1.3119931   1.5296751   0.43552196 -3.8295093  -1.105078\n",
      "   -2.9571974   0.5395242   1.4110634  -1.891544    1.839261\n",
      "   -1.0103552   1.4214919   0.81878555 -3.1543305  -2.4490614 ]\n",
      "  [ 0.2131815   0.0463079   2.5542054  -0.9284084  -2.1266398\n",
      "    1.2310258  -2.1391485   2.9588711  -1.4103144   0.7814084\n",
      "   -0.40864182 -1.0690196  -3.2982864  -0.05410185 -2.7681525\n",
      "   -1.2247558   0.65425557 -0.33789834  1.9997352  -2.0374649\n",
      "    1.2891186   1.224016    0.85831356 -2.4594085  -0.17166115\n",
      "   -0.989636   -3.4830256  -0.90197825 -0.15457037  1.0670104\n",
      "   -0.6133272  -0.6128544  -0.44651163  2.7221656   0.5849895\n",
      "   -2.3379762   1.9799956  -0.6998282   0.34045348  2.5152712\n",
      "   -0.9760443  -1.5176767  -1.8044798  -1.2876351   1.3010347\n",
      "    2.891918    1.5597717   1.028235   -2.598702   -0.8520462\n",
      "   -1.3455797  -0.01247176  1.376648    0.6923163  -0.89571697\n",
      "    0.26822206 -1.5917088  -0.54398996  0.5771829   1.8050923\n",
      "   -0.41080955  0.24514578  0.87952524 -2.898227    0.5955805\n",
      "   -0.53534853  0.35341153 -1.876469   -0.47136328  0.42669997\n",
      "   -0.18689327  0.8784496   0.12638916 -0.66951734  0.9458011\n",
      "   -1.8127785  -1.4964997   0.03887772  1.2006843  -1.8959113\n",
      "    0.93745303  1.7835507   0.69564515 -3.4413283   0.8841497\n",
      "   -0.4489163  -1.1815226  -3.7744844   0.66322273 -1.2616106\n",
      "   -3.6137323  -0.76970625 -3.5015678   0.05984874 -0.78058267\n",
      "    0.74010897 -0.13063148  0.20799387 -2.4626613  -0.9770742 ]]]\n",
      "\n",
      "y:\n",
      "[[False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in generator(sentences[0:5], next_words[0:5], 1):\n",
    "    print(\"X: \")\n",
    "    print(x)\n",
    "    print(\"\\ny:\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation, Bidirectional, LSTM, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback, EarlyStopping\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(s) for s in clean_songs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model!\n",
    "\n",
    "model = Sequential()\n",
    "# We will convert any text to a word embedding before sending it on its way.\n",
    "model.add(Bidirectional(LSTM(128), input_shape=(SEQUENCE_LEN, EMBEDDING_SIZE) ) )\n",
    "model.add(Dropout(DROPOUT))\n",
    "# Classification of next word.\n",
    "model.add(Dense(len(vocab))) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"LocalData/checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % (\n",
    "    len(vocab),\n",
    "    SEQUENCE_LEN,\n",
    "    MIN_WORD_FREQUENCY\n",
    ")\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "callbacks_list = [checkpoint, print_callback, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\heier\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "   211/154610 [..............................] - ETA: 28:35:17 - loss: 0.8058"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-39d5023d2747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n",
    "    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
